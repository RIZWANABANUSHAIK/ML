{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Life Expectancy (WHO) Prediction \n",
    "The data set from the kaggle:https://www.kaggle.com/datasets/kumarajarshi/life-expectancy-who\n",
    "### imports\n",
    "-here we import torch for gradients and networks<br>\n",
    "-pandas for data processing<br>\n",
    "-sci-kit learn for its usefull functions<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the csv file\n",
    "-next we will drop the features not relevant to the output, and the label itself and droping the na values <br> -next converting the categorail fields into 1 or 0's  <br> -printing the first 5 rows "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Life expectancy</th>\n",
       "      <th>Adult Mortality</th>\n",
       "      <th>infant deaths</th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>percentage expenditure</th>\n",
       "      <th>Hepatitis B</th>\n",
       "      <th>Measles</th>\n",
       "      <th>BMI</th>\n",
       "      <th>under-five deaths</th>\n",
       "      <th>Polio</th>\n",
       "      <th>...</th>\n",
       "      <th>Diphtheria</th>\n",
       "      <th>HIV/AIDS</th>\n",
       "      <th>GDP</th>\n",
       "      <th>Population</th>\n",
       "      <th>thinness  1-19 years</th>\n",
       "      <th>thinness 5-9 years</th>\n",
       "      <th>Income composition of resources</th>\n",
       "      <th>Schooling</th>\n",
       "      <th>Status_Developed</th>\n",
       "      <th>Status_Developing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>65.0</td>\n",
       "      <td>263.0</td>\n",
       "      <td>62</td>\n",
       "      <td>0.01</td>\n",
       "      <td>71.279624</td>\n",
       "      <td>65.0</td>\n",
       "      <td>1154</td>\n",
       "      <td>19.1</td>\n",
       "      <td>83</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>584.259210</td>\n",
       "      <td>33736494.0</td>\n",
       "      <td>17.2</td>\n",
       "      <td>17.3</td>\n",
       "      <td>0.479</td>\n",
       "      <td>10.1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>59.9</td>\n",
       "      <td>271.0</td>\n",
       "      <td>64</td>\n",
       "      <td>0.01</td>\n",
       "      <td>73.523582</td>\n",
       "      <td>62.0</td>\n",
       "      <td>492</td>\n",
       "      <td>18.6</td>\n",
       "      <td>86</td>\n",
       "      <td>58.0</td>\n",
       "      <td>...</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>612.696514</td>\n",
       "      <td>327582.0</td>\n",
       "      <td>17.5</td>\n",
       "      <td>17.5</td>\n",
       "      <td>0.476</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>59.9</td>\n",
       "      <td>268.0</td>\n",
       "      <td>66</td>\n",
       "      <td>0.01</td>\n",
       "      <td>73.219243</td>\n",
       "      <td>64.0</td>\n",
       "      <td>430</td>\n",
       "      <td>18.1</td>\n",
       "      <td>89</td>\n",
       "      <td>62.0</td>\n",
       "      <td>...</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>631.744976</td>\n",
       "      <td>31731688.0</td>\n",
       "      <td>17.7</td>\n",
       "      <td>17.7</td>\n",
       "      <td>0.470</td>\n",
       "      <td>9.9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>59.5</td>\n",
       "      <td>272.0</td>\n",
       "      <td>69</td>\n",
       "      <td>0.01</td>\n",
       "      <td>78.184215</td>\n",
       "      <td>67.0</td>\n",
       "      <td>2787</td>\n",
       "      <td>17.6</td>\n",
       "      <td>93</td>\n",
       "      <td>67.0</td>\n",
       "      <td>...</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>669.959000</td>\n",
       "      <td>3696958.0</td>\n",
       "      <td>17.9</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.463</td>\n",
       "      <td>9.8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>59.2</td>\n",
       "      <td>275.0</td>\n",
       "      <td>71</td>\n",
       "      <td>0.01</td>\n",
       "      <td>7.097109</td>\n",
       "      <td>68.0</td>\n",
       "      <td>3013</td>\n",
       "      <td>17.2</td>\n",
       "      <td>97</td>\n",
       "      <td>68.0</td>\n",
       "      <td>...</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>63.537231</td>\n",
       "      <td>2978599.0</td>\n",
       "      <td>18.2</td>\n",
       "      <td>18.2</td>\n",
       "      <td>0.454</td>\n",
       "      <td>9.5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Life expectancy   Adult Mortality  infant deaths  Alcohol  \\\n",
       "0              65.0            263.0             62     0.01   \n",
       "1              59.9            271.0             64     0.01   \n",
       "2              59.9            268.0             66     0.01   \n",
       "3              59.5            272.0             69     0.01   \n",
       "4              59.2            275.0             71     0.01   \n",
       "\n",
       "   percentage expenditure  Hepatitis B  Measles    BMI   under-five deaths   \\\n",
       "0               71.279624         65.0      1154   19.1                  83   \n",
       "1               73.523582         62.0       492   18.6                  86   \n",
       "2               73.219243         64.0       430   18.1                  89   \n",
       "3               78.184215         67.0      2787   17.6                  93   \n",
       "4                7.097109         68.0      3013   17.2                  97   \n",
       "\n",
       "   Polio  ...  Diphtheria    HIV/AIDS         GDP  Population  \\\n",
       "0    6.0  ...         65.0        0.1  584.259210  33736494.0   \n",
       "1   58.0  ...         62.0        0.1  612.696514    327582.0   \n",
       "2   62.0  ...         64.0        0.1  631.744976  31731688.0   \n",
       "3   67.0  ...         67.0        0.1  669.959000   3696958.0   \n",
       "4   68.0  ...         68.0        0.1   63.537231   2978599.0   \n",
       "\n",
       "    thinness  1-19 years   thinness 5-9 years  \\\n",
       "0                   17.2                 17.3   \n",
       "1                   17.5                 17.5   \n",
       "2                   17.7                 17.7   \n",
       "3                   17.9                 18.0   \n",
       "4                   18.2                 18.2   \n",
       "\n",
       "   Income composition of resources  Schooling  Status_Developed  \\\n",
       "0                            0.479       10.1                 0   \n",
       "1                            0.476       10.0                 0   \n",
       "2                            0.470        9.9                 0   \n",
       "3                            0.463        9.8                 0   \n",
       "4                            0.454        9.5                 0   \n",
       "\n",
       "   Status_Developing  \n",
       "0                  1  \n",
       "1                  1  \n",
       "2                  1  \n",
       "3                  1  \n",
       "4                  1  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = pd.read_csv(\"./Life Expectancy Data.csv\")\n",
    "features=features.drop([\"Country\",\"Year\"],axis=1).dropna()\n",
    "features=pd.get_dummies(features)\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### here  popping out the label\n",
    "* printing the first 5 Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    65.0\n",
       "1    59.9\n",
       "2    59.9\n",
       "3    59.5\n",
       "4    59.2\n",
       "Name: Life expectancy , dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = features.pop(\"Life expectancy \")\n",
    "labels.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### convertions\n",
    "* converting the dataframes into numpy arrays\n",
    "* next line  we will normalize the features so the training process goes faster \n",
    "* converting the arrays into tensors so we can perform ml operations on them\n",
    "* finally we are printing the shapes of features and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1649, 20]) torch.Size([1649, 1])\n"
     ]
    }
   ],
   "source": [
    "features = np.array(features)\n",
    "features = StandardScaler().fit_transform(features)\n",
    "\n",
    "features = torch.tensor(features, dtype=torch.float32)\n",
    "labels = torch.tensor(np.array(labels).reshape(-1,1), dtype=torch.float32)\n",
    "\n",
    "print(features.shape, labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### -creating a reasonally layered model with forst input size as 16 followed by Linear regression \n",
    "* printing the predictions shape and first five of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1649, 1])\n",
      "tensor([[-0.0662],\n",
      "        [-0.0662],\n",
      "        [-0.0662],\n",
      "        [-0.0662],\n",
      "        [-0.0662]], grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(20,11),\n",
    "    torch.nn.ReLU(), # activation functions\n",
    "    torch.nn.Linear(11,9),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(9,3),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(3,1)\n",
    "\n",
    ")\n",
    "\n",
    "preds = model(features)\n",
    "print(preds.shape)\n",
    "\n",
    "print(preds[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### the loss we will use Mean Squared Error - it is simple and most commom loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4889.3809, grad_fn=<MseLossBackward0>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.nn.functional import mse_loss\n",
    "\n",
    "loss = mse_loss(preds, labels)\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### the optimizer we will use is SGD-(stochastic gradient descent) to update network weights during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### we simply make predictions and calculate loss  and printing for 100000 epochs\n",
    "*then we will find gradients and optimize the model to reduce loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(8.1431, grad_fn=<MseLossBackward0>)\n",
      "tensor(6.1473, grad_fn=<MseLossBackward0>)\n",
      "tensor(5.5552, grad_fn=<MseLossBackward0>)\n",
      "tensor(5.2400, grad_fn=<MseLossBackward0>)\n",
      "tensor(4.8447, grad_fn=<MseLossBackward0>)\n",
      "tensor(4.5357, grad_fn=<MseLossBackward0>)\n",
      "tensor(4.2226, grad_fn=<MseLossBackward0>)\n",
      "tensor(4.2737, grad_fn=<MseLossBackward0>)\n",
      "tensor(4.2511, grad_fn=<MseLossBackward0>)\n",
      "tensor(4.3142, grad_fn=<MseLossBackward0>)\n",
      "tensor(4.4345, grad_fn=<MseLossBackward0>)\n",
      "tensor(4.2649, grad_fn=<MseLossBackward0>)\n",
      "tensor(4.2781, grad_fn=<MseLossBackward0>)\n",
      "tensor(4.0844, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.9659, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.8443, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.7625, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.7509, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.6634, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.6417, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.6706, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.5654, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.5421, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.4842, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.4953, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.4767, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.4472, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.4508, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.5407, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.5255, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.5461, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.5002, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.4403, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.4459, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.3664, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.3333, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.3288, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.3617, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.3438, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.3107, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.3183, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.3082, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.3275, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.3533, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.3389, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.2991, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.2771, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.2418, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.2926, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.2716, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.2307, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.2318, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.2245, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.2034, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.2320, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.2513, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.2245, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.2251, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.1806, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.1747, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.1798, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.1768, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.1971, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.2087, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.2041, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.2437, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.2300, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.2509, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.1954, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.2308, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.2097, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.2229, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.2096, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.2008, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.1920, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.1827, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.1712, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.2061, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.1961, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.1908, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.1770, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.1652, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.1539, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.1573, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.1415, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.1425, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.1185, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.1646, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.1112, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.1318, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.1551, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.1746, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.1749, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.1653, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.1832, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.1564, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.1579, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.1061, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.1223, grad_fn=<MseLossBackward0>)\n",
      "tensor(3.1131, grad_fn=<MseLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "epochs = 100000\n",
    "for epoch in range(epochs):\n",
    "    preds = model(features)\n",
    "    loss = mse_loss(preds, labels)\n",
    "    \n",
    "    if (epoch+1)%(epochs//100) == 0:\n",
    "        print(loss)\n",
    "        \n",
    "        \n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  here we are comparing that the actual value and our predictions are how far close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([75.8732], grad_fn=<AddBackward0>) tensor([75.9000])\n"
     ]
    }
   ],
   "source": [
    "i = 24\n",
    "preds = model(features[i])\n",
    "print(preds, labels[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here Saving the weights and biases of our model so we can load em up again whenever we want to make a prediction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),\"network_life.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "07521bee647cb038a9765ea0ecd3eab4d12b5f5b9eec9493f2d4acdd5b019b2b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
